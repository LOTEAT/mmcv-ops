{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from mmcv_ops.roi_align import RoIAlign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Creation\n",
    "# CPU Model\n",
    "roi_align_layer_cpu = RoIAlign((3, 3), 0.5, 0)\n",
    "# generate features randomly (bs, C, H, W)\n",
    "feats_cpu = torch.randn((1, 2, 10, 10), dtype=torch.float32, requires_grad=True)\n",
    "# create rois\n",
    "# 0 is batch idx\n",
    "# each roi is organised by (batch_idx, x1, y1, x2, y2)\n",
    "rois_cpu = torch.tensor([[0, 2, 2, 10, 10]], dtype=torch.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats:\n",
      "\n",
      "tensor([[[[-2.5713e-03,  1.5037e+00, -8.5731e-01, -9.5223e-01,  5.3696e-01,\n",
      "            1.6073e-04,  5.6176e-01, -8.9981e-02, -2.1373e+00,  1.3281e+00],\n",
      "          [ 1.5979e+00, -1.4464e+00,  9.6165e-02, -6.0188e-01, -1.6471e+00,\n",
      "            5.9958e-01, -4.4604e-01, -1.7704e+00,  7.2549e-01, -3.6659e-01],\n",
      "          [ 5.5192e-02, -3.2758e-01, -1.3232e+00, -7.2637e-01,  1.5397e+00,\n",
      "            9.8584e-01,  6.8755e-01,  5.5318e-01,  3.3241e-01,  7.3377e-01],\n",
      "          [-1.7188e+00,  1.3640e+00, -7.1641e-01,  9.0490e-01,  1.5488e+00,\n",
      "            1.1184e-01,  6.8294e-01, -1.5131e+00,  4.5585e-01, -8.5150e-01],\n",
      "          [ 1.2054e+00, -6.7155e-01, -4.5982e-01,  1.0026e-01,  8.7702e-02,\n",
      "           -1.1271e+00,  2.8566e+00, -7.3838e-01, -1.0185e+00,  6.3983e-01],\n",
      "          [ 5.9985e-01,  1.6295e-01,  2.6319e-01, -3.6429e-01, -1.0506e+00,\n",
      "            1.1890e+00,  1.9408e-01,  4.1470e-01,  7.0560e-02, -6.0905e-02],\n",
      "          [-1.2535e+00, -1.7469e+00, -1.1786e-01, -4.3168e-01,  1.0636e+00,\n",
      "            8.3630e-01,  6.1513e-01,  1.0380e+00,  1.5532e+00,  1.4934e+00],\n",
      "          [ 5.4445e-01, -9.7513e-01, -3.8435e-01,  1.2420e+00, -5.4430e-01,\n",
      "            1.1082e+00,  1.2876e+00,  2.5285e+00, -8.7236e-01, -7.1902e-01],\n",
      "          [ 1.4395e+00, -9.0739e-01,  1.4143e+00,  1.5700e-01,  5.2077e-01,\n",
      "           -1.6406e+00,  3.4351e-01,  1.9371e-01,  8.3276e-02, -9.8996e-01],\n",
      "          [-2.7480e-01, -9.6755e-01,  7.6009e-01,  2.4146e+00,  5.8890e-01,\n",
      "           -2.5451e-01,  1.6469e+00, -3.3443e-01, -6.9912e-01,  2.8067e+00]],\n",
      "\n",
      "         [[ 5.1961e-02,  6.4645e-01, -4.5526e-01,  1.4210e-01,  6.7376e-02,\n",
      "            7.6978e-01, -1.3984e+00, -6.7358e-01,  1.1635e+00,  1.0190e+00],\n",
      "          [-1.2436e+00, -4.2044e-01, -1.1149e+00, -6.3714e-01, -7.3302e-01,\n",
      "           -1.0859e+00,  1.0537e+00, -3.8746e-01, -1.4504e+00, -1.5666e-01],\n",
      "          [ 1.7216e+00,  1.3669e+00,  2.3610e-01, -7.5579e-01,  5.8658e-02,\n",
      "            2.8660e-01, -7.4256e-01, -7.7542e-01,  9.4027e-01, -1.1778e+00],\n",
      "          [-1.5537e+00, -2.2198e+00,  8.5608e-01,  1.2655e-01, -1.9012e-02,\n",
      "            2.1468e-01, -9.3249e-01, -2.4077e-02,  1.1718e+00, -8.0954e-02],\n",
      "          [-5.1406e-01, -1.8542e-02,  6.9220e-02, -6.5702e-01, -1.2030e-02,\n",
      "            2.8992e-01, -1.5821e+00, -9.4208e-01,  5.7422e-01, -8.8006e-01],\n",
      "          [-9.3535e-01, -1.6661e-01,  9.9769e-01, -9.7502e-01, -1.9828e+00,\n",
      "            6.6522e-01, -9.4640e-02,  9.6426e-01, -3.4649e-01, -1.1680e+00],\n",
      "          [-7.2285e-01, -4.2331e-01, -3.2913e-02,  6.2393e-01, -2.8782e-01,\n",
      "           -4.3459e-01, -1.3692e+00,  2.2079e+00, -3.6652e-01, -3.5826e-01],\n",
      "          [-6.5394e-01,  7.7037e-01,  1.8557e+00,  6.2918e-01, -3.8010e-01,\n",
      "            1.3555e+00, -4.5039e-01, -7.7422e-01, -1.5385e-01,  6.5165e-02],\n",
      "          [-6.2774e-01, -1.5331e+00,  2.1026e-02, -1.1056e+00, -2.3633e+00,\n",
      "           -5.1699e-01,  1.5342e+00, -1.2430e+00,  6.9948e-01, -7.0639e-01],\n",
      "          [ 2.9988e-01,  5.3729e-01,  1.3744e+00,  1.0026e+00, -1.5431e+00,\n",
      "            1.7700e+00,  9.6329e-02, -1.2739e+00,  1.1854e+00, -4.2317e-01]]]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# print feats\n",
    "print('feats:\\n')\n",
    "print(feats_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. `forward` Function in RoIAlign\n",
    "The following is the forward function in RoIAlign Module.\n",
    "```python\n",
    "    def forward(self, input: torch.Tensor, rois: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input: NCHW images\n",
    "            rois: Bx5 boxes. First column is the index into N.\\\n",
    "                The other 4 columns are xyxy.\n",
    "        \"\"\"\n",
    "        return roi_align(input, rois, self.output_size, self.spatial_scale,\n",
    "                         self.sampling_ratio, self.pool_mode, self.aligned)\n",
    "```\n",
    "We can find that it calls `roi_align` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. `forward` Function in RoIAlignFunction\n",
    "Actually, `roi_align` is the `forward` function in `RoIAlignFunction`.\n",
    "\n",
    "```python\n",
    "    def forward(ctx: Any,\n",
    "                input: torch.Tensor,\n",
    "                rois: torch.Tensor,\n",
    "                output_size: int,\n",
    "                spatial_scale: float = 1.0,\n",
    "                sampling_ratio: int = 0,\n",
    "                pool_mode: str = 'avg',\n",
    "                aligned: bool = True) -> torch.Tensor:\n",
    "        device = input.device\n",
    "        # In our settings, ctx.output_size = (3, 3)\n",
    "        ctx.output_size = _pair(output_size)\n",
    "        # spatial_scale = 0.5\n",
    "        ctx.spatial_scale = spatial_scale\n",
    "        # If sampling_ratio > 0, we sample sampling_ratio * sampling_ratio points in each block\n",
    "        # else, the number of points we sample is based some rules\n",
    "        ctx.sampling_ratio = sampling_ratio\n",
    "        assert pool_mode in ('max', 'avg')\n",
    "        # Here pool mode is 1\n",
    "        ctx.pool_mode = 0 if pool_mode == 'max' else 1\n",
    "        # aligned = True\n",
    "        ctx.aligned = aligned\n",
    "        # input_shape = (1, 2, 10, 10)\n",
    "        ctx.input_shape = input.size()\n",
    "\n",
    "        assert rois.size(1) == 5, 'RoI must be (idx, x1, y1, x2, y2)!'\n",
    "        # output_shape = (1, 2, 3, 3)\n",
    "        output_shape = (rois.size(0), input.size(1), ctx.output_size[0],\n",
    "                        ctx.output_size[1])\n",
    "        # output\n",
    "        output = input.new_zeros(output_shape)\n",
    "        if ctx.pool_mode == 0:\n",
    "            argmax_y = input.new_zeros(output_shape)\n",
    "            argmax_x = input.new_zeros(output_shape)\n",
    "        else:\n",
    "            argmax_y = input.new_zeros(0)\n",
    "            argmax_x = input.new_zeros(0)\n",
    "        if device == 'cpu':\n",
    "            roi_align_forward = ext_module.roi_align_forward_cpu\n",
    "        else:\n",
    "            roi_align_forward = ext_module.roi_align_forward_cuda\n",
    "        roi_align_forward(input,\n",
    "                          rois,\n",
    "                          output,\n",
    "                          argmax_y,\n",
    "                          argmax_x,\n",
    "                          aligned_height=ctx.output_size[0],\n",
    "                          aligned_width=ctx.output_size[1],\n",
    "                          spatial_scale=ctx.spatial_scale,\n",
    "                          sampling_ratio=ctx.sampling_ratio,\n",
    "                          pool_mode=ctx.pool_mode,\n",
    "                          aligned=ctx.aligned)\n",
    "\n",
    "        ctx.save_for_backward(rois, argmax_y, argmax_x)\n",
    "        return output\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. `roi_align_forward_cpu`\n",
    "Let's see `roi_align_forward_cpu` firstly.\n",
    "\n",
    "```cpp\n",
    "void roi_align_forward_cpu(Tensor input, Tensor rois, Tensor output,\n",
    "                                Tensor argmax_y, Tensor argmax_x,\n",
    "                                int aligned_height, int aligned_width,\n",
    "                                float spatial_scale, int sampling_ratio,\n",
    "                                int pool_mode, bool aligned) {\n",
    "  // output_size = 1 * 2 * 3 * 3 = 18\n",
    "  int output_size = output.numel();\n",
    "  // channels = 2\n",
    "  int channels = input.size(1);\n",
    "  // height = 10\n",
    "  int height = input.size(2);\n",
    "  // width = 10\n",
    "  int width = input.size(3);\n",
    "\n",
    "  AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
    "      input.scalar_type(), \"ROIAlign_forward\", [&] {\n",
    "        ROIAlignForward<scalar_t>(\n",
    "            output_size, input.data_ptr<scalar_t>(), rois.data_ptr<scalar_t>(),\n",
    "            output.data_ptr<scalar_t>(), argmax_y.data_ptr<scalar_t>(),\n",
    "            argmax_x.data_ptr<scalar_t>(), aligned_height, aligned_width,\n",
    "            static_cast<scalar_t>(spatial_scale), sampling_ratio, pool_mode,\n",
    "            aligned, channels, height, width);\n",
    "      });\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.ROIAlignForward\n",
    "In `roi_align_forward_cpu`, it calls `ROIAlignForward` function.\n",
    "\n",
    "```cpp\n",
    "template <typename T>\n",
    "void ROIAlignForward(const int nthreads, const T* input, const T* rois,\n",
    "                     T* output, T* argmax_y, T* argmax_x,\n",
    "                     const int pooled_height, const int pooled_width,\n",
    "                     const T spatial_scale, const int sampling_ratio,\n",
    "                     const int pool_mode,  // 0 - max pool, 1 - avg pool\n",
    "                     const bool aligned, const int channels, const int height,\n",
    "                     const int width) {\n",
    "  // nthreads are the output size, which is equal to \n",
    "  // nrois * channels * pooled_width * pooled_height\n",
    "  int n_rois = nthreads / channels / pooled_width / pooled_height;\n",
    "  // (n, c, ph, pw) is an element in the pooled output\n",
    "  // can be parallelized using omp\n",
    "  // #pragma omp parallel for num_threads(32)\n",
    "  // we iterate each roi\n",
    "  for (int n = 0; n < n_rois; n++) {\n",
    "    // Note that in C++, the Tensor type is organised by 1D array\n",
    "    // Therefore, we need to calculate the start index of output for n-th roi\n",
    "    // output is (n_rois, channels, pooled_width, pooled_height)\n",
    "    // For n-th roi, the start index should be `n * channels * pooled_width * pooled_height`\n",
    "    int index_n = n * channels * pooled_width * pooled_height;\n",
    "    // offset of n-th roi\n",
    "    const T* offset_rois = rois + n * 5;\n",
    "    // get batch idx\n",
    "    int roi_batch_ind = offset_rois[0];\n",
    "\n",
    "    // Do not use rounding; this implementation detail is critical\n",
    "    T offset = aligned ? (T)0.5 : (T)0.0;\n",
    "    // offset is just a trick, whether to align\n",
    "    // Remember that after convolution, the feature map is a downsample image\n",
    "    // And spatial_scale is the downsample rate\n",
    "    // roi_start_w = 0.5, roi_start_h = 0.5, roi_end_w = 4.5, roi_end_h = 4.5\n",
    "    T roi_start_w = offset_rois[1] * spatial_scale - offset;\n",
    "    T roi_start_h = offset_rois[2] * spatial_scale - offset;\n",
    "    T roi_end_w = offset_rois[3] * spatial_scale - offset;\n",
    "    T roi_end_h = offset_rois[4] * spatial_scale - offset;\n",
    "    // the width and height of roi in feature map\n",
    "    // roi_width = 4, roi_height = 4\n",
    "    T roi_width = roi_end_w - roi_start_w;\n",
    "    T roi_height = roi_end_h - roi_start_h;\n",
    "    if (aligned) {\n",
    "      AT_ASSERTM(roi_width >= 0 && roi_height >= 0,\n",
    "                 \"ROIs in ROIAlign cannot have non-negative size!\");\n",
    "    } else {  // for backward-compatibility only\n",
    "      roi_width = std::max(roi_width, (T)1.);\n",
    "      roi_height = std::max(roi_height, (T)1.);\n",
    "    }\n",
    "    // Notice that T is float\n",
    "    // Each output unit length corresponds to the length of the roi\n",
    "    // In our case, bin_size_h = 1.33, bin_size_w = 1.33\n",
    "    T bin_size_h = static_cast<T>(roi_height) / static_cast<T>(pooled_height);\n",
    "    T bin_size_w = static_cast<T>(roi_width) / static_cast<T>(pooled_width);\n",
    "\n",
    "    // We use roi_bin_grid to sample the grid and mimic integral\n",
    "    // roi_bin_grid_h = 2\n",
    "    // roi_bin_grid_w = 2\n",
    "    int roi_bin_grid_h = (sampling_ratio > 0)\n",
    "                             ? sampling_ratio\n",
    "                             : ceilf(roi_height / pooled_height);  // e.g., = 2\n",
    "    int roi_bin_grid_w =\n",
    "        (sampling_ratio > 0) ? sampling_ratio : ceilf(roi_width / pooled_width);\n",
    "\n",
    "    // When the grid is empty, output zeros == 0/1, instead of NaN.\n",
    "    // count = 4\n",
    "    const T count = std::max(roi_bin_grid_h * roi_bin_grid_w, 1);  // e.g. = 4\n",
    "\n",
    "    // we want to precalculate indices and weights shared by all channels,\n",
    "    // this is the key point of optimization\n",
    "    std::vector<PreCalc<T>> pre_calc(roi_bin_grid_h * roi_bin_grid_w *\n",
    "                                     pooled_width * pooled_height);\n",
    "    pre_calc_for_bilinear_interpolate(\n",
    "        height, width, pooled_height, pooled_width, roi_bin_grid_h,\n",
    "        roi_bin_grid_w, roi_start_h, roi_start_w, bin_size_h, bin_size_w,\n",
    "        roi_bin_grid_h, roi_bin_grid_w, pre_calc);\n",
    "    // before diving into more details, you should read section 5 & 6\n",
    "    // iteration for each channel\n",
    "    for (int c = 0; c < channels; c++) {\n",
    "      // index_n is the start index of n-th roi\n",
    "      // index_n_c is the start index of c-th channel of n-th roi\n",
    "      int index_n_c = index_n + c * pooled_width * pooled_height;\n",
    "      // ptr of feats\n",
    "      const T* offset_input =\n",
    "          input + (roi_batch_ind * channels + c) * height * width;\n",
    "      int pre_calc_index = 0;\n",
    "      // iteration for pooled_height\n",
    "      for (int ph = 0; ph < pooled_height; ph++) {\n",
    "        // iteration for pooled_width\n",
    "        for (int pw = 0; pw < pooled_width; pw++) {\n",
    "          // index of pooled pixel\n",
    "          int index = index_n_c + ph * pooled_width + pw;\n",
    "\n",
    "          T output_val = 0.;\n",
    "          T maxval = -10000;\n",
    "          T maxidx_y = -1.f, maxidx_x = -1.f;\n",
    "          for (int iy = 0; iy < roi_bin_grid_h; iy++) {\n",
    "            // y coordinate\n",
    "            const T y = roi_start_h + ph * bin_size_h +\n",
    "                        static_cast<T>(iy + .5f) * bin_size_h /\n",
    "                            static_cast<T>(roi_bin_grid_h);\n",
    "            for (int ix = 0; ix < roi_bin_grid_w; ix++) {\n",
    "              // x coordinate\n",
    "              const T x = roi_start_w + pw * bin_size_w +\n",
    "                          static_cast<T>(ix + .5f) * bin_size_w /\n",
    "                              static_cast<T>(roi_bin_grid_w);\n",
    "              PreCalc<T> pc = pre_calc[pre_calc_index];\n",
    "              T val = pc.w1 * offset_input[pc.pos1] +\n",
    "                      pc.w2 * offset_input[pc.pos2] +\n",
    "                      pc.w3 * offset_input[pc.pos3] +\n",
    "                      pc.w4 * offset_input[pc.pos4];\n",
    "              if (val > maxval) {\n",
    "                maxval = val;\n",
    "                maxidx_y = y;\n",
    "                maxidx_x = x;\n",
    "              }\n",
    "              output_val += val;\n",
    "              pre_calc_index += 1;\n",
    "            }\n",
    "          }\n",
    "          if (pool_mode == 0) {\n",
    "            // We do max pooling inside a bin\n",
    "            output[index] = maxval;\n",
    "            argmax_y[index] = maxidx_y;\n",
    "            argmax_x[index] = maxidx_x;\n",
    "          } else if (pool_mode == 1) {\n",
    "            // We do average (integral) pooling inside a bin\n",
    "            output[index] = output_val / count;\n",
    "          }  // if\n",
    "        }    // for pw\n",
    "      }      // for ph\n",
    "    }        // for c\n",
    "  }          // for n\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. PreCalc\n",
    "One import data structure in `roi_align_forward_cpu` is `PreCalc`.\n",
    "```cpp\n",
    "template <typename T>\n",
    "struct PreCalc {\n",
    "  // positions and weights\n",
    "  int pos1;\n",
    "  int pos2;\n",
    "  int pos3;\n",
    "  int pos4;\n",
    "  T w1;\n",
    "  T w2;\n",
    "  T w3;\n",
    "  T w4;\n",
    "};\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. `pre_calc_for_bilinear_interpolate` Function\n",
    "\n",
    "```cpp\n",
    "template <typename T>\n",
    "void pre_calc_for_bilinear_interpolate(\n",
    "    const int height, const int width, const int pooled_height,\n",
    "    const int pooled_width, const int iy_upper, const int ix_upper,\n",
    "    T roi_start_h, T roi_start_w, T bin_size_h, T bin_size_w,\n",
    "    int roi_bin_grid_h, int roi_bin_grid_w, std::vector<PreCalc<T>>& pre_calc) {\n",
    "  // height = 10, width = 10, pooled_height = 3, pooled_width = 3\n",
    "  // iy_upper = 2, ix_upper = 2, roi_start_h = 0.5, roi_start_w = 0.5\n",
    "  // bin_size_h = 1.33, bin_size_w = 1.33, roi_bin_grid_h = 2, roi_bin_grid_w = 2\n",
    "\n",
    "  // index counter\n",
    "  int pre_calc_index = 0;\n",
    "  // iteration for pooled_height\n",
    "  for (int ph = 0; ph < pooled_height; ph++) {\n",
    "    // iteration for pooled_width\n",
    "    for (int pw = 0; pw < pooled_width; pw++) {\n",
    "      // iteration for sampling points\n",
    "      // we will sample iy_upper point per column\n",
    "      for (int iy = 0; iy < iy_upper; iy++) {\n",
    "        // yy is the y coordinate of sampling point \n",
    "        // roi_start_h is y coordinate of top left corner of roi\n",
    "        // bin_size_h is gap in roi for per pooling pixel\n",
    "        // roi_start_h + ph * bin_size_h is the y coordinate of top left corner of roi for ph-th pooling block\n",
    "        // static_cast<T>(iy + .5f), move to center\n",
    "        // static_cast<T>(iy + .5f) / static_cast<T>(roi_bin_grid_h) percentage for iy-th sampling point in pooling area\n",
    "        // static_cast<T>(iy + .5f) * bin_size_h / static_cast<T>(roi_bin_grid_h) is the gap for top left corner of roi for ph-th pooling block\n",
    "        const T yy = roi_start_h + ph * bin_size_h +\n",
    "                     static_cast<T>(iy + .5f) * bin_size_h /\n",
    "                         static_cast<T>(roi_bin_grid_h);  // e.g., 0.5, 1.5\n",
    "        // iteration for sampling points\n",
    "        // we will sample ix_upper point per row\n",
    "        for (int ix = 0; ix < ix_upper; ix++) {\n",
    "          // xx is the x coordinate of sampling point\n",
    "          // the same with yy\n",
    "          const T xx = roi_start_w + pw * bin_size_w +\n",
    "                       static_cast<T>(ix + .5f) * bin_size_w /\n",
    "                           static_cast<T>(roi_bin_grid_w);\n",
    "\n",
    "          T x = xx;\n",
    "          T y = yy;\n",
    "          // deal with: inverse elements are out of feature map boundary\n",
    "          if (y < -1.0 || y > height || x < -1.0 || x > width) {\n",
    "            // empty\n",
    "            PreCalc<T> pc;\n",
    "            pc.pos1 = 0;\n",
    "            pc.pos2 = 0;\n",
    "            pc.pos3 = 0;\n",
    "            pc.pos4 = 0;\n",
    "            pc.w1 = 0;\n",
    "            pc.w2 = 0;\n",
    "            pc.w3 = 0;\n",
    "            pc.w4 = 0;\n",
    "            pre_calc[pre_calc_index] = pc;\n",
    "            pre_calc_index += 1;\n",
    "            continue;\n",
    "          }\n",
    "\n",
    "          if (y <= 0) {\n",
    "            y = 0;\n",
    "          }\n",
    "          if (x <= 0) {\n",
    "            x = 0;\n",
    "          }\n",
    "          // calculate for around points for bilinear interplotation\n",
    "          int y_low = (int)y;\n",
    "          int x_low = (int)x;\n",
    "          int y_high;\n",
    "          int x_high;\n",
    "\n",
    "          if (y_low >= height - 1) {\n",
    "            y_high = y_low = height - 1;\n",
    "            y = (T)y_low;\n",
    "          } else {\n",
    "            y_high = y_low + 1;\n",
    "          }\n",
    "\n",
    "          if (x_low >= width - 1) {\n",
    "            x_high = x_low = width - 1;\n",
    "            x = (T)x_low;\n",
    "          } else {\n",
    "            x_high = x_low + 1;\n",
    "          }\n",
    "          // y_low-y distance\n",
    "          T ly = y - y_low;\n",
    "          // x_low-x distance\n",
    "          T lx = x - x_low;\n",
    "          // y_high-y distance & x_high-x distance\n",
    "          T hy = 1. - ly, hx = 1. - lx;\n",
    "          // the weights of bilinear interplotation\n",
    "          // Remember in pixels, the denominator is 1\n",
    "          // w1, w2, w3, w4 should be (x2-x)(y2-y), (y2-y)(x-x1), (y-y1)(x2-x), (y-y1)(x-x1), respectively\n",
    "          T w1 = hy * hx, w2 = hy * lx, w3 = ly * hx, w4 = ly * lx;\n",
    "\n",
    "          // save weights and indices\n",
    "          PreCalc<T> pc;\n",
    "          pc.pos1 = y_low * width + x_low;\n",
    "          pc.pos2 = y_low * width + x_high;\n",
    "          pc.pos3 = y_high * width + x_low;\n",
    "          pc.pos4 = y_high * width + x_high;\n",
    "          pc.w1 = w1;\n",
    "          pc.w2 = w2;\n",
    "          pc.w3 = w3;\n",
    "          pc.w4 = w4;\n",
    "          pre_calc[pre_calc_index] = pc;\n",
    "\n",
    "          pre_calc_index += 1;\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "align roi cpu:\n",
      "\n",
      "tensor([[[[-0.6085, -0.5002, -0.5573],\n",
      "          [ 0.0212, -0.4653,  1.0975],\n",
      "          [-0.1427, -0.1005,  0.2524]],\n",
      "\n",
      "         [[-0.1365, -0.6620, -0.5117],\n",
      "          [-0.1408,  0.1157, -0.0446],\n",
      "          [-0.3691, -0.0722, -0.2154]]]], grad_fn=<RoIAlignFunctionBackward>)\n"
     ]
    }
   ],
   "source": [
    "align_roi_cpu = roi_align_layer_cpu(feats_cpu, rois_cpu)\n",
    "print('align roi cpu:\\n')\n",
    "print(align_roi_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Creation\n",
    "# GPU Model\n",
    "roi_align_layer_cuda = RoIAlign((3, 3), 0.5, 0).cuda()\n",
    "# generate features randomly (bs, C, H, W)\n",
    "feats_cuda = torch.randn((1, 2, 10, 10), dtype=torch.float32, requires_grad=True, device='cuda:0')\n",
    "# create rois\n",
    "# 0 is batch idx\n",
    "# each roi is organised by (batch_idx, x1, y1, x2, y2)\n",
    "rois_cuda = torch.tensor([[0, 2, 2, 10, 10]], dtype=torch.float32, requires_grad=True, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats:\n",
      "\n",
      "tensor([[[[ 0.4523, -1.0065, -0.3902,  1.8674, -1.6499,  0.9775, -0.6862,\n",
      "           -0.1537, -0.1833, -0.6323],\n",
      "          [-0.3402,  0.6857,  1.0672, -0.2833,  0.6593,  1.1190,  1.1162,\n",
      "           -0.9814, -0.1445,  0.2993],\n",
      "          [ 0.2471, -0.7748,  1.0461,  0.1611, -0.6186, -0.1185,  0.2856,\n",
      "            0.4536,  1.1910, -1.1816],\n",
      "          [ 0.8882,  0.5833,  0.7704,  0.3234,  0.3315,  1.8253, -0.0405,\n",
      "           -1.2682,  0.3178, -0.3674],\n",
      "          [ 0.2915, -0.4005, -0.2978,  0.0839, -0.4258, -0.0033, -0.2221,\n",
      "            0.4304, -0.9117,  0.8872],\n",
      "          [-0.8741, -0.0435,  0.3163,  0.0767,  0.1527,  0.9254, -0.5713,\n",
      "            0.9510,  0.9856, -0.1897],\n",
      "          [-1.1491,  1.1246,  0.0521, -0.3353, -0.3466,  0.2733,  0.4524,\n",
      "            0.6890, -0.3549, -1.8094],\n",
      "          [ 0.0428, -0.7628,  0.2676,  0.1854,  0.9270,  0.6253, -0.5556,\n",
      "           -0.5676,  0.6673,  1.2532],\n",
      "          [ 0.3715, -0.1489,  0.8443,  0.1007, -0.1244,  1.0739, -0.8319,\n",
      "            0.2981,  1.1218, -0.2544],\n",
      "          [-0.7347,  0.4445, -0.2855, -0.9035, -1.1150, -0.0274,  1.5049,\n",
      "            1.6176,  1.1122, -1.7404]],\n",
      "\n",
      "         [[-0.2759,  1.0251, -0.8907, -1.5358, -0.6725, -0.5623,  0.5077,\n",
      "            0.3562,  1.0260,  0.9518],\n",
      "          [ 0.6938,  0.7407, -1.6202, -0.5901,  0.6602, -0.2538,  0.4730,\n",
      "           -0.7626, -0.8040, -1.2223],\n",
      "          [-0.8499, -0.0321,  0.7325,  0.2760,  0.9367, -0.1858,  0.3694,\n",
      "           -0.3119, -0.1724,  1.0251],\n",
      "          [-1.2376,  1.3934,  2.2873, -0.8493,  0.3304, -1.1353,  0.3282,\n",
      "            0.9759,  0.0870,  1.4549],\n",
      "          [-0.0868,  0.1102,  0.4543,  0.1304, -1.2860,  2.4844, -0.0711,\n",
      "            1.4100, -1.5434,  0.8304],\n",
      "          [-0.9314,  0.3642,  1.1515, -0.5740, -1.1620,  0.1366, -0.8983,\n",
      "           -1.1023, -1.6131,  0.3077],\n",
      "          [ 0.5514,  0.6946, -2.1913,  1.1845,  0.1018, -0.7531, -0.1865,\n",
      "            1.4035,  0.7842, -2.0815],\n",
      "          [ 0.0302,  2.2679,  0.4716,  1.1819, -0.8722, -0.2078, -0.4933,\n",
      "            0.3659, -1.4884, -0.5234],\n",
      "          [ 0.3712, -1.8545, -0.4990, -0.0030, -0.5220,  0.1166, -1.2342,\n",
      "            0.0607,  0.6422, -1.0436],\n",
      "          [ 0.7675,  0.0353, -0.0671,  0.8426,  0.9965, -1.1462, -0.8579,\n",
      "            0.0112,  0.2590,  0.6032]]]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# print feats\n",
    "print('feats:\\n')\n",
    "print(feats_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "align roi cuda:\n",
      "\n",
      "tensor([[[[ 0.3442,  0.4738,  0.1665],\n",
      "          [ 0.2105,  0.5752,  0.0360],\n",
      "          [-0.0495,  0.0818, -0.0454]],\n",
      "\n",
      "         [[ 0.1569, -0.7118,  0.2772],\n",
      "          [ 0.7443,  0.6116,  0.2956],\n",
      "          [ 0.5070,  0.3987, -0.5090]]]], device='cuda:0',\n",
      "       grad_fn=<RoIAlignFunctionBackward>)\n"
     ]
    }
   ],
   "source": [
    "align_roi_cuda = roi_align_layer_cuda(feats_cuda, rois_cuda)\n",
    "print('align roi cuda:\\n')\n",
    "print(align_roi_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. roi_align_forward_cuda\n",
    "\n",
    "Let's see `roi_align_forward_cuda` then.\n",
    "\n",
    "```cpp\n",
    "void roi_align_forward_cuda(Tensor input, Tensor rois, Tensor output,\n",
    "                                       Tensor argmax_y, Tensor argmax_x,\n",
    "                                       int aligned_height, int aligned_width,\n",
    "                                       float spatial_scale, int sampling_ratio,\n",
    "                                       int pool_mode, bool aligned) {\n",
    "  int output_size = output.numel();\n",
    "  int channels = input.size(1);\n",
    "  int height = input.size(2);\n",
    "  int width = input.size(3);\n",
    "\n",
    "  at::cuda::CUDAGuard device_guard(input.device());\n",
    "  cudaStream_t stream = at::cuda::getCurrentCUDAStream();\n",
    "  AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
    "      input.scalar_type(), \"roi_align_forward_cuda_kernel\", [&] {\n",
    "        roi_align_forward_cuda_kernel<scalar_t>\n",
    "            <<<GET_BLOCKS(output_size), THREADS_PER_BLOCK, 0, stream>>>(\n",
    "                output_size, input.data_ptr<scalar_t>(),\n",
    "                rois.data_ptr<scalar_t>(), output.data_ptr<scalar_t>(),\n",
    "                argmax_y.data_ptr<scalar_t>(), argmax_x.data_ptr<scalar_t>(),\n",
    "                aligned_height, aligned_width,\n",
    "                static_cast<scalar_t>(spatial_scale), sampling_ratio, pool_mode,\n",
    "                aligned, channels, height, width);\n",
    "      });\n",
    "\n",
    "  AT_CUDA_CHECK(cudaGetLastError());\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. roi_align_forward_cuda_kernel\n",
    "Actually, we can find that `roi_align_forward_cuda_kernel` is almost the same with `roi_align_forward_cpu_kernel`.\n",
    "This implementation is multi-thread and is based on the number of RoIs.\n",
    "\n",
    "```cpp\n",
    "template <typename T>\n",
    "__global__ void roi_align_forward_cuda_kernel(\n",
    "    const int nthreads, const T* input, const T* rois, T* output, T* argmax_y,\n",
    "    T* argmax_x, const int pooled_height, const int pooled_width,\n",
    "    const T spatial_scale, const int sampling_ratio,\n",
    "    const int pool_mode,  // 0 - max pool, 1 - avg pool\n",
    "    const bool aligned, const int channels, const int height, const int width) {\n",
    "  CUDA_1D_KERNEL_LOOP(index, nthreads) {\n",
    "    // (n, c, ph, pw) is an element in the pooled output\n",
    "    int pw = index % pooled_width;\n",
    "    int ph = (index / pooled_width) % pooled_height;\n",
    "    int c = (index / pooled_width / pooled_height) % channels;\n",
    "    int n = index / pooled_width / pooled_height / channels;\n",
    "\n",
    "    const T* offset_rois = rois + n * 5;\n",
    "    int roi_batch_ind = offset_rois[0];\n",
    "\n",
    "    // Do not using rounding; this implementation detail is critical\n",
    "    T offset = aligned ? (T)0.5 : (T)0.0;\n",
    "    T roi_start_w = offset_rois[1] * spatial_scale - offset;\n",
    "    T roi_start_h = offset_rois[2] * spatial_scale - offset;\n",
    "    T roi_end_w = offset_rois[3] * spatial_scale - offset;\n",
    "    T roi_end_h = offset_rois[4] * spatial_scale - offset;\n",
    "\n",
    "    T roi_width = roi_end_w - roi_start_w;\n",
    "    T roi_height = roi_end_h - roi_start_h;\n",
    "    if (!aligned) {  // for backward-compatibility only\n",
    "      roi_width = max(roi_width, (T)1.);\n",
    "      roi_height = max(roi_height, (T)1.);\n",
    "    }\n",
    "\n",
    "    T bin_size_h = static_cast<T>(roi_height) / static_cast<T>(pooled_height);\n",
    "    T bin_size_w = static_cast<T>(roi_width) / static_cast<T>(pooled_width);\n",
    "\n",
    "    const T* offset_input =\n",
    "        input + (roi_batch_ind * channels + c) * height * width;\n",
    "\n",
    "    // We use roi_bin_grid to sample the grid and mimic integral\n",
    "    int roi_bin_grid_h =\n",
    "        (sampling_ratio > 0)\n",
    "            ? sampling_ratio\n",
    "            : static_cast<int>(ceilf(roi_height / pooled_height));\n",
    "    int roi_bin_grid_w =\n",
    "        (sampling_ratio > 0)\n",
    "            ? sampling_ratio\n",
    "            : static_cast<int>(ceilf(roi_width / pooled_width));\n",
    "\n",
    "    if (pool_mode == 0) {\n",
    "      // We do max pooling inside a bin\n",
    "      T maxval = -FLT_MAX;\n",
    "      T maxidx_y = -1.f, maxidx_x = -1.f;\n",
    "      for (int iy = 0; iy < roi_bin_grid_h; iy++) {\n",
    "        const T y = roi_start_h + ph * bin_size_h +\n",
    "                    static_cast<T>(iy + .5f) * bin_size_h /\n",
    "                        static_cast<T>(roi_bin_grid_h);\n",
    "        for (int ix = 0; ix < roi_bin_grid_w; ix++) {\n",
    "          const T x = roi_start_w + pw * bin_size_w +\n",
    "                      static_cast<T>(ix + .5f) * bin_size_w /\n",
    "                          static_cast<T>(roi_bin_grid_w);\n",
    "          T val =\n",
    "              bilinear_interpolate(offset_input, height, width, y, x, index);\n",
    "          if (val > maxval) {\n",
    "            maxval = val;\n",
    "            maxidx_y = y;\n",
    "            maxidx_x = x;\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "      output[index] = maxval;\n",
    "      argmax_y[index] = maxidx_y;\n",
    "      argmax_x[index] = maxidx_x;\n",
    "    } else if (pool_mode == 1) {\n",
    "      // We do average pooling inside a bin\n",
    "      const T count = max(roi_bin_grid_h * roi_bin_grid_w, 1);\n",
    "      T output_val = 0.;\n",
    "      for (int iy = 0; iy < roi_bin_grid_h; iy++) {\n",
    "        const T y = roi_start_h + ph * bin_size_h +\n",
    "                    static_cast<T>(iy + .5f) * bin_size_h /\n",
    "                        static_cast<T>(roi_bin_grid_h);\n",
    "        for (int ix = 0; ix < roi_bin_grid_w; ix++) {\n",
    "          const T x = roi_start_w + pw * bin_size_w +\n",
    "                      static_cast<T>(ix + .5f) * bin_size_w /\n",
    "                          static_cast<T>(roi_bin_grid_w);\n",
    "          T val =\n",
    "              bilinear_interpolate(offset_input, height, width, y, x, index);\n",
    "          output_val += val;\n",
    "        }\n",
    "      }\n",
    "      output[index] = output_val / count;\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. roi_align_backward_cpu\n",
    "\n",
    "```cpp\n",
    "void roi_align_backward_cpu(Tensor grad_output, Tensor rois,\n",
    "                                 Tensor argmax_y, Tensor argmax_x,\n",
    "                                 Tensor grad_input, int aligned_height,\n",
    "                                 int aligned_width, float spatial_scale,\n",
    "                                 int sampling_ratio, int pool_mode,\n",
    "                                 bool aligned) {\n",
    "  int output_size = grad_output.numel();\n",
    "  int channels = grad_input.size(1);\n",
    "  int height = grad_input.size(2);\n",
    "  int width = grad_input.size(3);\n",
    "\n",
    "  // get stride values to ensure indexing into gradients is correct.\n",
    "  int n_stride = grad_output.stride(0);\n",
    "  int c_stride = grad_output.stride(1);\n",
    "  int h_stride = grad_output.stride(2);\n",
    "  int w_stride = grad_output.stride(3);\n",
    "\n",
    "  AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
    "      grad_output.scalar_type(), \"ROIAlign_backward\", [&] {\n",
    "        ROIAlignBackward<scalar_t>(\n",
    "            output_size, grad_output.data_ptr<scalar_t>(),\n",
    "            rois.data_ptr<scalar_t>(), argmax_y.data_ptr<scalar_t>(),\n",
    "            argmax_x.data_ptr<scalar_t>(), grad_input.data_ptr<scalar_t>(),\n",
    "            aligned_height, aligned_width, static_cast<scalar_t>(spatial_scale),\n",
    "            sampling_ratio, pool_mode, aligned, channels, height, width,\n",
    "            n_stride, c_stride, h_stride, w_stride);\n",
    "      });\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. `backward` Function in `RoIAlignFunction`\n",
    "We also should know the backward process. Note that the `grad_output` should be a tensor whose dimension is (n_rois, C, output_size, output_size). In our setting, the dimension is (1, 2, 3, 3).\n",
    "\n",
    "```python\n",
    "    def backward(ctx: Any, grad_output: torch.Tensor) -> tuple:\n",
    "        rois, argmax_y, argmax_x = ctx.saved_tensors\n",
    "        device = rois.device\n",
    "        grad_input = grad_output.new_zeros(ctx.input_shape)\n",
    "        # complex head architecture may cause grad_output uncontiguous.\n",
    "        grad_output = grad_output.contiguous()\n",
    "        if device == 'cpu':\n",
    "            roi_align_backward = ext_module.roi_align_backward_cpu\n",
    "        else:\n",
    "            roi_align_backward = ext_module.roi_align_backward_cuda\n",
    "        roi_align_backward(grad_output,\n",
    "                           rois,\n",
    "                           argmax_y,\n",
    "                           argmax_x,\n",
    "                           grad_input,\n",
    "                           aligned_height=ctx.output_size[0],\n",
    "                           aligned_width=ctx.output_size[1],\n",
    "                           spatial_scale=ctx.spatial_scale,\n",
    "                           sampling_ratio=ctx.sampling_ratio,\n",
    "                           pool_mode=ctx.pool_mode,\n",
    "                           aligned=ctx.aligned)\n",
    "        return grad_input, None, None, None, None, None, None\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. roi_align_backward_cpu\n",
    "This is the entrance to back propagation.\n",
    "\n",
    "```cpp\n",
    "void roi_align_backward_cpu(Tensor grad_output, Tensor rois,\n",
    "                                 Tensor argmax_y, Tensor argmax_x,\n",
    "                                 Tensor grad_input, int aligned_height,\n",
    "                                 int aligned_width, float spatial_scale,\n",
    "                                 int sampling_ratio, int pool_mode,\n",
    "                                 bool aligned) {\n",
    "  int output_size = grad_output.numel();\n",
    "  int channels = grad_input.size(1);\n",
    "  int height = grad_input.size(2);\n",
    "  int width = grad_input.size(3);\n",
    "\n",
    "  // get stride values to ensure indexing into gradients is correct.\n",
    "  int n_stride = grad_output.stride(0);\n",
    "  int c_stride = grad_output.stride(1);\n",
    "  int h_stride = grad_output.stride(2);\n",
    "  int w_stride = grad_output.stride(3);\n",
    "\n",
    "  AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
    "      grad_output.scalar_type(), \"ROIAlign_backward\", [&] {\n",
    "        ROIAlignBackward<scalar_t>(\n",
    "            output_size, grad_output.data_ptr<scalar_t>(),\n",
    "            rois.data_ptr<scalar_t>(), argmax_y.data_ptr<scalar_t>(),\n",
    "            argmax_x.data_ptr<scalar_t>(), grad_input.data_ptr<scalar_t>(),\n",
    "            aligned_height, aligned_width, static_cast<scalar_t>(spatial_scale),\n",
    "            sampling_ratio, pool_mode, aligned, channels, height, width,\n",
    "            n_stride, c_stride, h_stride, w_stride);\n",
    "      });\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. ROIAlignBackward\n",
    "\n",
    "It is easy for you to derive the Back Propagation formula.\n",
    "\n",
    "```cpp\n",
    "template <typename T>\n",
    "void ROIAlignBackward(const int nthreads, const T* grad_output, const T* rois,\n",
    "                      const T* argmax_y, const T* argmax_x, T* grad_input,\n",
    "                      const int pooled_height, const int pooled_width,\n",
    "                      const T spatial_scale, const int sampling_ratio,\n",
    "                      const int pool_mode,  // 0 - max pool, 1 - avg pool\n",
    "                      const bool aligned, const int channels, const int height,\n",
    "                      const int width, const int n_stride, const int c_stride,\n",
    "                      const int h_stride, const int w_stride) {\n",
    "  // nthreads = 1 * 2 * 10 * 10 = 200\n",
    "  // For now, grad_out is a grad matrix whose dimension is (1, 2, 3, 3)\n",
    "  // the dimension of rois is (1, 5)\n",
    "  // argmax_y, argmax_x is memorized in forward step\n",
    "  // grad_input is a zero matrix whose dimension is (1, 2, 10, 10)\n",
    "  // pooled_height = 3\n",
    "  // pooled_width = 3\n",
    "  // spatial_scale = 0.5\n",
    "  // sampling_ratio = 0\n",
    "  // pool_mode = 0\n",
    "  // aligned = True\n",
    "  // channels = 2\n",
    "  // height = 10\n",
    "  // width = 10\n",
    "  // n_stride = 18\n",
    "  // c_stride = 9\n",
    "  // h_stride = 3\n",
    "  // w_stride = 1\n",
    "  for (int index = 0; index < nthreads; index++) {\n",
    "    // (n, c, ph, pw) is an element in the pooled output\n",
    "    int pw = index % pooled_width;\n",
    "    int ph = (index / pooled_width) % pooled_height;\n",
    "    int c = (index / pooled_width / pooled_height) % channels;\n",
    "    int n = index / pooled_width / pooled_height / channels;\n",
    "    // for n-th roi\n",
    "    const T* offset_rois = rois + n * 5;\n",
    "    // get batch idx\n",
    "    int roi_batch_ind = offset_rois[0];\n",
    "\n",
    "    // Do not use rounding; this implementation detail is critical\n",
    "    T offset = aligned ? (T)0.5 : (T)0.0;\n",
    "    // calculate the roi coordinate, width and height\n",
    "    T roi_start_w = offset_rois[1] * spatial_scale - offset;\n",
    "    T roi_start_h = offset_rois[2] * spatial_scale - offset;\n",
    "    T roi_end_w = offset_rois[3] * spatial_scale - offset;\n",
    "    T roi_end_h = offset_rois[4] * spatial_scale - offset;\n",
    "\n",
    "    T roi_width = roi_end_w - roi_start_w;\n",
    "    T roi_height = roi_end_h - roi_start_h;\n",
    "    if (aligned) {\n",
    "      AT_ASSERTM(roi_width >= 0 && roi_height >= 0,\n",
    "                 \"ROIs in ROIAlign do not have non-negative size!\");\n",
    "    } else {  // for backward-compatibility only\n",
    "      roi_width = std::max(roi_width, (T)1.);\n",
    "      roi_height = std::max(roi_height, (T)1.);\n",
    "    }\n",
    "    // Notice that T is float\n",
    "    // Each output unit length corresponds to the length of the roi\n",
    "    // In our case, bin_size_h = 1.33, bin_size_w = 1.33\n",
    "    T bin_size_h = static_cast<T>(roi_height) / static_cast<T>(pooled_height);\n",
    "    T bin_size_w = static_cast<T>(roi_width) / static_cast<T>(pooled_width);\n",
    "\n",
    "    // get n-th feature map's grad\n",
    "    T* offset_grad_input =\n",
    "        grad_input + ((roi_batch_ind * channels + c) * height * width);\n",
    "    // get (n, c, ph, pw) element in grad_output\n",
    "    int output_offset = n * n_stride + c * c_stride;\n",
    "    const T* offset_grad_output = grad_output + output_offset;\n",
    "    const T grad_output_this_bin =\n",
    "        offset_grad_output[ph * h_stride + pw * w_stride];\n",
    "\n",
    "    if (pool_mode == 0) {\n",
    "      // We do max pooling inside a bin\n",
    "      // get max point\n",
    "      T y = argmax_y[index], x = argmax_x[index];\n",
    "      if (y != -1.f) {\n",
    "        T w1, w2, w3, w4;\n",
    "        int x_low, x_high, y_low, y_high;\n",
    "        // Before diving into more details, you should read Sec. 13,\n",
    "        bilinear_interpolate_gradient(height, width, y, x, w1, w2, w3, w4,\n",
    "                                      x_low, x_high, y_low, y_high, index);\n",
    "        // w * grad_output\n",
    "        T g1 = grad_output_this_bin * w1;\n",
    "        T g2 = grad_output_this_bin * w2;\n",
    "        T g3 = grad_output_this_bin * w3;\n",
    "        T g4 = grad_output_this_bin * w4;\n",
    "\n",
    "        if (x_low >= 0 && x_high >= 0 && y_low >= 0 && y_high >= 0) {\n",
    "          // atomic add is not needed for now since it is single threaded\n",
    "          add(offset_grad_input + y_low * width + x_low, static_cast<T>(g1));\n",
    "          add(offset_grad_input + y_low * width + x_high, static_cast<T>(g2));\n",
    "          add(offset_grad_input + y_high * width + x_low, static_cast<T>(g3));\n",
    "          add(offset_grad_input + y_high * width + x_high, static_cast<T>(g4));\n",
    "        }  // if\n",
    "      }    // mode\n",
    "    } else if (pool_mode == 1) {\n",
    "      // We do average (integral) pooling inside a bin\n",
    "      // We use roi_bin_grid to sample the grid and mimic integral\n",
    "      int roi_bin_grid_h =\n",
    "          (sampling_ratio > 0)\n",
    "              ? sampling_ratio\n",
    "              : ceilf(roi_height / pooled_height);  // e.g., = 2\n",
    "      int roi_bin_grid_w = (sampling_ratio > 0)\n",
    "                               ? sampling_ratio\n",
    "                               : ceilf(roi_width / pooled_width);\n",
    "\n",
    "      const T count = roi_bin_grid_h * roi_bin_grid_w;  // e.g. = 4\n",
    "      for (int iy = 0; iy < roi_bin_grid_h; iy++) {\n",
    "        const T y = roi_start_h + ph * bin_size_h +\n",
    "                    static_cast<T>(iy + .5f) * bin_size_h /\n",
    "                        static_cast<T>(roi_bin_grid_h);  // e.g., 0.5, 1.5\n",
    "        for (int ix = 0; ix < roi_bin_grid_w; ix++) {\n",
    "          const T x = roi_start_w + pw * bin_size_w +\n",
    "                      static_cast<T>(ix + .5f) * bin_size_w /\n",
    "                          static_cast<T>(roi_bin_grid_w);\n",
    "\n",
    "          T w1, w2, w3, w4;\n",
    "          int x_low, x_high, y_low, y_high;\n",
    "\n",
    "          bilinear_interpolate_gradient(height, width, y, x, w1, w2, w3, w4,\n",
    "                                        x_low, x_high, y_low, y_high, index);\n",
    "\n",
    "          T g1 = grad_output_this_bin * w1 / count;\n",
    "          T g2 = grad_output_this_bin * w2 / count;\n",
    "          T g3 = grad_output_this_bin * w3 / count;\n",
    "          T g4 = grad_output_this_bin * w4 / count;\n",
    "\n",
    "          if (x_low >= 0 && x_high >= 0 && y_low >= 0 && y_high >= 0) {\n",
    "            // atomic add is not needed for now since it is single threaded\n",
    "            add(offset_grad_input + y_low * width + x_low, static_cast<T>(g1));\n",
    "            add(offset_grad_input + y_low * width + x_high, static_cast<T>(g2));\n",
    "            add(offset_grad_input + y_high * width + x_low, static_cast<T>(g3));\n",
    "            add(offset_grad_input + y_high * width + x_high,\n",
    "                static_cast<T>(g4));\n",
    "          }  // if\n",
    "        }    // ix\n",
    "      }      // iy\n",
    "    }        // mode\n",
    "  }          // for\n",
    "}  // ROIAlignBackward\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 13. bilinear_interpolate_gradient\n",
    "This function helps us to calculate the gradient of bilinear interpolatation.\n",
    "\n",
    "```cpp\n",
    "template <typename T>\n",
    "void bilinear_interpolate_gradient(const int height, const int width, T y, T x,\n",
    "                                   T& w1, T& w2, T& w3, T& w4, int& x_low,\n",
    "                                   int& x_high, int& y_low, int& y_high,\n",
    "                                   const int index /* index for debug only*/) {\n",
    "  // deal with cases that inverse elements are out of feature map boundary\n",
    "  if (y < -1.0 || y > height || x < -1.0 || x > width) {\n",
    "    // empty\n",
    "    w1 = w2 = w3 = w4 = 0.;\n",
    "    x_low = x_high = y_low = y_high = -1;\n",
    "    return;\n",
    "  }\n",
    "\n",
    "  if (y <= 0) y = 0;\n",
    "  if (x <= 0) x = 0;\n",
    "\n",
    "  y_low = (int)y;\n",
    "  x_low = (int)x;\n",
    "\n",
    "  if (y_low >= height - 1) {\n",
    "    y_high = y_low = height - 1;\n",
    "    y = (T)y_low;\n",
    "  } else {\n",
    "    y_high = y_low + 1;\n",
    "  }\n",
    "\n",
    "  if (x_low >= width - 1) {\n",
    "    x_high = x_low = width - 1;\n",
    "    x = (T)x_low;\n",
    "  } else {\n",
    "    x_high = x_low + 1;\n",
    "  }\n",
    "\n",
    "  T ly = y - y_low;\n",
    "  T lx = x - x_low;\n",
    "  T hy = 1. - ly, hx = 1. - lx;\n",
    "\n",
    "  // reference in forward\n",
    "  // T v1 = input[y_low * width + x_low];\n",
    "  // T v2 = input[y_low * width + x_high];\n",
    "  // T v3 = input[y_high * width + x_low];\n",
    "  // T v4 = input[y_high * width + x_high];\n",
    "  // T val = (w1 * v1 + w2 * v2 + w3 * v3 + w4 * v4);\n",
    "\n",
    "  w1 = hy * hx, w2 = hy * lx, w3 = ly * hx, w4 = ly * lx;\n",
    "\n",
    "  return;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. add\n",
    "Add function.\n",
    "```cpp\n",
    "template <class T>\n",
    "inline void add(T* address, const T& val) {\n",
    "  *address += val;\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0069, 0.0556, 0.0625, 0.0625, 0.0556, 0.0069, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0556, 0.4444, 0.5000, 0.5000, 0.4444, 0.0556, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0625, 0.5000, 0.5625, 0.5625, 0.5000, 0.0625, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0625, 0.5000, 0.5625, 0.5625, 0.5000, 0.0625, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0556, 0.4444, 0.5000, 0.5000, 0.4444, 0.0556, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0069, 0.0556, 0.0625, 0.0625, 0.0556, 0.0069, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0069, 0.0556, 0.0625, 0.0625, 0.0556, 0.0069, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0556, 0.4444, 0.5000, 0.5000, 0.4444, 0.0556, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0625, 0.5000, 0.5625, 0.5625, 0.5000, 0.0625, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0625, 0.5000, 0.5625, 0.5625, 0.5000, 0.0625, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0556, 0.4444, 0.5000, 0.5000, 0.4444, 0.0556, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0069, 0.0556, 0.0625, 0.0625, 0.0556, 0.0069, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000]]]])\n"
     ]
    }
   ],
   "source": [
    "align_roi_sum_cpu = align_roi_cpu.sum()\n",
    "align_roi_sum_cpu.backward()\n",
    "print(feats_cpu.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. roi_align_backward_cuda\n",
    "\n",
    "```cpp\n",
    "void roi_align_backward_cuda(Tensor grad_output, Tensor rois,\n",
    "                                        Tensor argmax_y, Tensor argmax_x,\n",
    "                                        Tensor grad_input, int aligned_height,\n",
    "                                        int aligned_width, float spatial_scale,\n",
    "                                        int sampling_ratio, int pool_mode,\n",
    "                                        bool aligned) {\n",
    "  int output_size = grad_output.numel();\n",
    "  int channels = grad_input.size(1);\n",
    "  int height = grad_input.size(2);\n",
    "  int width = grad_input.size(3);\n",
    "\n",
    "  at::cuda::CUDAGuard device_guard(grad_output.device());\n",
    "  cudaStream_t stream = at::cuda::getCurrentCUDAStream();\n",
    "  AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
    "      grad_output.scalar_type(), \"roi_align_backward_cuda_kernel\", [&] {\n",
    "        roi_align_backward_cuda_kernel<scalar_t>\n",
    "            <<<GET_BLOCKS(output_size), THREADS_PER_BLOCK, 0, stream>>>(\n",
    "                output_size, grad_output.data_ptr<scalar_t>(),\n",
    "                rois.data_ptr<scalar_t>(), argmax_y.data_ptr<scalar_t>(),\n",
    "                argmax_x.data_ptr<scalar_t>(), grad_input.data_ptr<scalar_t>(),\n",
    "                aligned_height, aligned_width,\n",
    "                static_cast<scalar_t>(spatial_scale), sampling_ratio, pool_mode,\n",
    "                aligned, channels, height, width);\n",
    "      });\n",
    "\n",
    "  AT_CUDA_CHECK(cudaGetLastError());\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. roi_align_backward_cuda_kernel\n",
    "It is almost the same with `roi_align_backward_cpu_kernel`. Note that in cuda kernel we should use `atomicAdd`.\n",
    "\n",
    "```cpp\n",
    "template <typename T>\n",
    "__global__ void roi_align_backward_cuda_kernel(\n",
    "    const int nthreads, const T* grad_output, const T* rois, const T* argmax_y,\n",
    "    const T* argmax_x, T* grad_input, const int pooled_height,\n",
    "    const int pooled_width, const T spatial_scale, const int sampling_ratio,\n",
    "    const int pool_mode,  // 0 - max pool, 1 - avg pool\n",
    "    const bool aligned, const int channels, const int height, const int width) {\n",
    "  CUDA_1D_KERNEL_LOOP(index, nthreads) {\n",
    "    // (n, c, ph, pw) is an element in the pooled output\n",
    "    int pw = index % pooled_width;\n",
    "    int ph = (index / pooled_width) % pooled_height;\n",
    "    int c = (index / pooled_width / pooled_height) % channels;\n",
    "    int n = index / pooled_width / pooled_height / channels;\n",
    "\n",
    "    const T grad_output_this_bin = grad_output[index];\n",
    "\n",
    "    const T* offset_rois = rois + n * 5;\n",
    "    int roi_batch_ind = offset_rois[0];\n",
    "    T* offset_grad_input =\n",
    "        grad_input + ((roi_batch_ind * channels + c) * height * width);\n",
    "\n",
    "    if (pool_mode == 0) {\n",
    "      T y = argmax_y[index], x = argmax_x[index];\n",
    "      if (y != -1.f) {\n",
    "        T w1, w2, w3, w4;\n",
    "        int x_low, x_high, y_low, y_high;\n",
    "        bilinear_interpolate_gradient(height, width, y, x, w1, w2, w3, w4,\n",
    "                                      x_low, x_high, y_low, y_high, index);\n",
    "\n",
    "        if (x_low >= 0 && x_high >= 0 && y_low >= 0 && y_high >= 0) {\n",
    "          atomicAdd(offset_grad_input + y_low * width + x_low,\n",
    "                    grad_output_this_bin * w1);\n",
    "          atomicAdd(offset_grad_input + y_low * width + x_high,\n",
    "                    grad_output_this_bin * w2);\n",
    "          atomicAdd(offset_grad_input + y_high * width + x_low,\n",
    "                    grad_output_this_bin * w3);\n",
    "          atomicAdd(offset_grad_input + y_high * width + x_high,\n",
    "                    grad_output_this_bin * w4);\n",
    "        }\n",
    "      }\n",
    "    } else if (pool_mode == 1) {\n",
    "      // Do not using rounding; this implementation detail is critical\n",
    "      T offset = aligned ? (T)0.5 : (T)0.0;\n",
    "      T roi_start_w = offset_rois[1] * spatial_scale - offset;\n",
    "      T roi_start_h = offset_rois[2] * spatial_scale - offset;\n",
    "      T roi_end_w = offset_rois[3] * spatial_scale - offset;\n",
    "      T roi_end_h = offset_rois[4] * spatial_scale - offset;\n",
    "\n",
    "      T roi_width = roi_end_w - roi_start_w;\n",
    "      T roi_height = roi_end_h - roi_start_h;\n",
    "      if (!aligned) {  // for backward-compatibility only\n",
    "        roi_width = max(roi_width, (T)1.);\n",
    "        roi_height = max(roi_height, (T)1.);\n",
    "      }\n",
    "\n",
    "      T bin_size_h = static_cast<T>(roi_height) / static_cast<T>(pooled_height);\n",
    "      T bin_size_w = static_cast<T>(roi_width) / static_cast<T>(pooled_width);\n",
    "\n",
    "      // We use roi_bin_grid to sample the grid and mimic integral\n",
    "      int roi_bin_grid_h =\n",
    "          (sampling_ratio > 0)\n",
    "              ? sampling_ratio\n",
    "              : static_cast<int>(ceilf(roi_height / pooled_height));\n",
    "      int roi_bin_grid_w =\n",
    "          (sampling_ratio > 0)\n",
    "              ? sampling_ratio\n",
    "              : static_cast<int>(ceilf(roi_width / pooled_width));\n",
    "\n",
    "      // We do average (integral) pooling inside a bin\n",
    "      const T count = roi_bin_grid_h * roi_bin_grid_w;  // e.g. = 4\n",
    "\n",
    "      for (int iy = 0; iy < roi_bin_grid_h; iy++) {\n",
    "        const T y = roi_start_h + ph * bin_size_h +\n",
    "                    static_cast<T>(iy + .5f) * bin_size_h /\n",
    "                        static_cast<T>(roi_bin_grid_h);\n",
    "        for (int ix = 0; ix < roi_bin_grid_w; ix++) {\n",
    "          const T x = roi_start_w + pw * bin_size_w +\n",
    "                      static_cast<T>(ix + .5f) * bin_size_w /\n",
    "                          static_cast<T>(roi_bin_grid_w);\n",
    "\n",
    "          T w1, w2, w3, w4;\n",
    "          int x_low, x_high, y_low, y_high;\n",
    "          bilinear_interpolate_gradient(height, width, y, x, w1, w2, w3, w4,\n",
    "                                        x_low, x_high, y_low, y_high, index);\n",
    "\n",
    "          if (x_low >= 0 && x_high >= 0 && y_low >= 0 && y_high >= 0) {\n",
    "            atomicAdd(offset_grad_input + y_low * width + x_low,\n",
    "                      grad_output_this_bin * w1 / count);\n",
    "            atomicAdd(offset_grad_input + y_low * width + x_high,\n",
    "                      grad_output_this_bin * w2 / count);\n",
    "            atomicAdd(offset_grad_input + y_high * width + x_low,\n",
    "                      grad_output_this_bin * w3 / count);\n",
    "            atomicAdd(offset_grad_input + y_high * width + x_high,\n",
    "                      grad_output_this_bin * w4 / count);\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0069, 0.0556, 0.0625, 0.0625, 0.0556, 0.0069, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0556, 0.4444, 0.5000, 0.5000, 0.4444, 0.0556, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0625, 0.5000, 0.5625, 0.5625, 0.5000, 0.0625, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0625, 0.5000, 0.5625, 0.5625, 0.5000, 0.0625, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0556, 0.4444, 0.5000, 0.5000, 0.4444, 0.0556, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0069, 0.0556, 0.0625, 0.0625, 0.0556, 0.0069, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0069, 0.0556, 0.0625, 0.0625, 0.0556, 0.0069, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0556, 0.4444, 0.5000, 0.5000, 0.4444, 0.0556, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0625, 0.5000, 0.5625, 0.5625, 0.5000, 0.0625, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0625, 0.5000, 0.5625, 0.5625, 0.5000, 0.0625, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0556, 0.4444, 0.5000, 0.5000, 0.4444, 0.0556, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0069, 0.0556, 0.0625, 0.0625, 0.0556, 0.0069, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "align_roi_sum_cuda = align_roi_cuda.sum()\n",
    "align_roi_sum_cuda.backward()\n",
    "print(feats_cuda.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
